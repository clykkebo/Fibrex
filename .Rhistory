# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
# Load data
load(params$input)
# Update taxa_names
## Species
phy.sp <- tax_glom(phy, taxrank = "Species")
taxnames <- as.vector(tax_table(phy.sp)[,7])
taxdub <- taxnames[duplicated(taxnames)]
for (tax in taxdub){
taxnames[taxnames == tax] <- paste(tax, seq(length(taxnames[taxnames == tax])), sep = "_")
}
taxa_names(phy.sp) <- taxnames
## Genus
phy.ge <- tax_glom(phy, taxrank = "Genus")
taxnames <- as.vector(tax_table(phy.ge)[,6])
taxdub <- taxnames[duplicated(taxnames)]
for (tax in taxdub){
taxnames[taxnames == tax] <- paste(tax, seq(length(taxnames[taxnames == tax])), sep = "_")
}
taxa_names(phy.ge) <- taxnames
## Family
phy.fa <- tax_glom(phy, taxrank = "Family")
taxnames <- as.vector(tax_table(phy.fa)[,5])
taxdub <- taxnames[duplicated(taxnames)]
for (tax in taxdub){
taxnames[taxnames == tax] <- paste(tax, seq(length(taxnames[taxnames == tax])), sep = "_")
}
taxa_names(phy.fa) <- taxnames
## Order
phy.or <- tax_glom(phy, taxrank = "Order")
taxnames <- as.vector(tax_table(phy.or)[,4])
taxdub <- taxnames[duplicated(taxnames)]
for (tax in taxdub){
taxnames[taxnames == tax] <- paste(tax, seq(length(taxnames[taxnames == tax])), sep = "_")
}
taxa_names(phy.or) <- taxnames
## Class
phy.cl <- tax_glom(phy, taxrank = "Class")
taxnames <- as.vector(tax_table(phy.cl)[,3])
taxdub <- taxnames[duplicated(taxnames)]
for (tax in taxdub){
taxnames[taxnames == tax] <- paste(tax, seq(length(taxnames[taxnames == tax])), sep = "_")
}
taxa_names(phy.cl) <- taxnames
## Phylum
phy.ph <- tax_glom(phy, taxrank = "Phylum")
taxnames <- as.vector(tax_table(phy.ph)[,2])
taxdub <- taxnames[duplicated(taxnames)]
for (tax in taxdub){
taxnames[taxnames == tax] <- paste(tax, seq(length(taxnames[taxnames == tax])), sep = "_")
}
taxa_names(phy.ph) <- taxnames
# save agglomerated phyloseq objects
save(phy.sp, phy.ge, phy.fa, phy.or, phy.cl, phy.ph, file = "R_objects/Agglomerated.RData")
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
# load data
load("R_objects/Agglomerated.RData")
params <- readRDS("R_objects/params_description.RDS")
# Transform data
phy.rel <- transform_sample_counts(phy.ph, fun = function(x) x/sum(x)*100)
dat <- psmelt(phy.rel)
# summarise per sample
sumsample <- dat %>%
filter(Abundance > 0) %>%
group_by(Sample) %>%
summarise(pct_0 = n(),
pct_0.1 = sum(Abundance < 0.1),
pct_0_1 = sum(Abundance >= 0.1 & Abundance < 1),
pct_1_10 = sum(Abundance >= 1 & Abundance < 10),
pct_10 = sum(Abundance > 10)) %>%
pivot_longer(-Sample,
names_to = c("Cutoff"),
values_to = "Count") %>%
group_by(Cutoff) %>%
summarise(sample_mean = mean(Count),
sample_sd = sd(Count))
# summarise total
sumall <- dat %>%
filter(Abundance > 0) %>%
group_by(OTU) %>%
summarise(Abundance = mean(Abundance)) %>%
summarise(pct_0 = n(),
pct_0.1 = sum(Abundance < 0.1),
pct_0_1 = sum(Abundance >= 0.1 & Abundance < 1),
pct_1_10 = sum(Abundance >= 1 & Abundance < 10),
pct_10 = sum(Abundance > 10)) %>%
pivot_longer(cols = everything(),
names_to = c("Cutoff"),
values_to = "Count")
# Combine
output <- full_join(sumall, sumsample)
output$Cutoff <- c("All", "n < 0.1%", "0.1% < n < 1.0%", "1.0% < n < 10%", "10%  < n")
# Create output table
kable(output, row.names = F,digits = 2, caption = 'Count of phyla in general and per sample',align = "r") %>%
kable_classic(full_width = F, position = "left")
# Filter by abundance, then rank
phy.top <- filter_abundance(phy.rel) %>% filter_rank(min.rank = 19)
#Melt data
dat <- suppressWarnings(psmelt(phy.top))
colnames(dat)[c(1,4)] <- c("Taxa","Sample_ID")
# Sort taxa
dat.sort <- sort_taxa(dat)
summary(dat$SampleID)
ise
summarise(dat$SampleID)
summary(dat[dat$SampleID])
head(dat$Phylum)
head(dat$Phylum,300)
# Filter by abundance, then rank
phy.top <- filter_abundance(phy.rel) %>% filter_rank(min.rank = 19)
#Melt data
dat <- suppressWarnings(psmelt(phy.top))
colnames(dat)[c(1,4)] <- c("Taxa","SampleID")
# Sort taxa
dat.sort <- sort_taxa(dat)
names(dat)
distinct(dat$Phylum) %>% view()
distinct(dat$Phylum) %>% view() #
# Filter by abundance, then rank
phy.top <- filter_abundance(phy.rel) %>% filter_rank(min.rank = 19)
#Melt data
dat <- suppressWarnings(psmelt(phy.top))
colnames(dat)[c(1,4)] <- c("Taxa","SampleID")
# Sort taxa
dat.sort <- sort_taxa(dat)
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(ggpubr)
library(rstatix)
library(kableExtra)
library(picante)
library(plotly)
# Create used folders if missing
if (!file.exists("R_objects")) dir.create(file.path(getwd(), "R_objects"))
if (!file.exists("plots")) dir.create(file.path(getwd(), "plots"))
if (!file.exists("plots/adiv")) dir.create(file.path(getwd(), "plots/adiv"))
if (!file.exists("tables")) dir.create(file.path(getwd(), "tables"))
if (!file.exists("scripts")) dir.create(file.path(getwd(), "scripts"))
# Save params
saveRDS(params, file = "R_objects/Adiv_params.RDS")
params <- readRDS("R_objects/Adiv_params.RDS")
# load data
load(params$input)
load("scripts/adiv.Rdata")
INDECES <- c("Observed","Shannon", "FaithPD", "Chao1","Evenness")
# Calculate data
adat <- Calculate_alpha_div(phy, methods = INDECES)
# Save the phyloseq object
save(adat, INDECES, file="R_objects/AlphaDiversity.RData")
write.csv(adat, "export/alpha-diversity.csv", row.names = FALSE)
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")
### Test observed richness
FORMULA <- as.formula(paste("Observed ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")
## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
wilcox_test(FORMULA) %>%
adjust_pvalue(method = "BH") %>%
add_significance("p.adj") %>%
add_x_position(x = params$batch) %>%
p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)
# Format for
if (sum(stat.test$p.adj.signif != "ns") == 0) {
stat.sig <- stat.test %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}
# Create plot
p <- ggboxplot(adat, x = params$batch, y = "Observed",
color = params$batch, palette = "jco",
add = "jitter")
p.obs <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)
### Pilous Evenness
FORMULA <- as.formula(paste("Evenness ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")
## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
wilcox_test(FORMULA) %>%
adjust_pvalue(method = "BH") %>%
add_significance("p.adj") %>%
add_x_position(x = params$batch) %>%
p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)
# Format for
if (sum(stat.test$p.adj.signif != "ns") == 0) {
stat.sig <- stat.test %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}
# Create plot
p <- ggboxplot(adat, x = params$batch, y = "Evenness",
color = params$batch, palette = "jco",
add = "jitter")
p.eve <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)
### Test Evenness
FORMULA <- as.formula(paste("Evenness ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")
## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
wilcox_test(FORMULA) %>%
adjust_pvalue(method = "BH") %>%
add_significance("p.adj") %>%
add_x_position(x = params$batch) %>%
p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)
# Format for
if (sum(stat.test$p.adj.signif != "ns") == 0) {
stat.sig <- stat.test %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}
# Create plot
p <- ggboxplot(adat, x = params$batch, y = "Evenness",
color = params$batch, palette = "jco",
add = "jitter")
p.eve <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)
### Test shannon diversity index
# Run statistical test of batch effect
FORMULA <- as.formula(paste("Shannon ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")
## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
wilcox_test(FORMULA) %>%
adjust_pvalue(method = "BH") %>%
add_significance("p.adj") %>%
add_x_position(x = params$batch) %>%
p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)
# Format for
if (sum(stat.test$p.adj.signif != "ns") == 0) {
stat.sig <- stat.test %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
} else {
stat.sig <- stat.test[stat.test$p.adj.signif != "ns",] %>%
add_y_position(step.increase = 0.25) %>%
mutate(y.position = seq(min(y.position), max(y.position),length.out = n()))
}
# Create plot
p <- ggboxplot(adat, x = params$batch, y = "Shannon", color = params$batch, palette = "jco", add = "jitter")
p.sdi <- p + stat_pvalue_manual(stat.sig, label = "p.adj.format",tip.length = 0)
# If there is a significant batch effect, then it will be necessary to correct following tests for this effect.
# Test Faith phylogenetic distance
FORMULA <- as.formula(paste("FaithPD ~", params$batch, sep = " "))
compare_means(FORMULA,  data = adat, method = "kruskal")
## If significant:
# Perform pairwise comparisons
stat.test <- adat %>%
wilcox_test(FORMULA) %>%
adjust_pvalue(method = "BH") %>%
add_significance("p.adj") %>%
add_x_position(x = params$batch) %>%
p_format("p.adj", accuracy = 0.0001, trailing.zero = TRUE, new.col = TRUE)
params <- readRDS("R_objects/Adiv_params.RDS")
# load data
load(params$input)
load("scripts/adiv.Rdata")
INDECES <- c("Observed","Shannon", "FaithPD", "Chao1","Evenness")
# Calculate data
adat <- Calculate_alpha_div(phy, methods = INDECES)
# Save the phyloseq object
save(adat, INDECES, file="R_objects/AlphaDiversity.RData")
write.csv(adat, "export/alpha-diversity.csv", row.names = FALSE)
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
params <- readRDS("R_objects/Adiv_params.RDS")
# Load data
load("R_objects/AlphaDiversity.RData")
head(adat$FaithPD, 200)
summary(adat$FaithPD)
params <- readRDS(file = "R_objects/import_params.RDS")
load("scripts/adiv.Rdata")
# Set indeces
INDECES <- as.vector(str_split(params$indeces,pattern = "\\|",simplify = TRUE))
## First phyloseq object
# load data
load("R_objects/Phyloseq.Rdata")
# Calculate data
adat <- calculate_alpha_diversity(phy, methods = INDECES)
# Calculate data
adat <- calculate_alpha_diversity(phy, INDECES = INDECES)
# Filter by abundance, then rank
phy.top <- filter_abundance(phy.rel) %>% filter_rank(min.rank = 19)
# load data
load("R_objects/Agglomerated.RData")
params <- readRDS("R_objects/params_description.RDS")
# Transform data
phy.rel <- transform_sample_counts(phy.ph, fun = function(x) x/sum(x)*100)
dat <- psmelt(phy.rel)
# summarise per sample
sumsample <- dat %>%
filter(Abundance > 0) %>%
group_by(Sample) %>%
summarise(pct_0 = n(),
pct_0.1 = sum(Abundance < 0.1),
pct_0_1 = sum(Abundance >= 0.1 & Abundance < 1),
pct_1_10 = sum(Abundance >= 1 & Abundance < 10),
pct_10 = sum(Abundance > 10)) %>%
pivot_longer(-Sample,
names_to = c("Cutoff"),
values_to = "Count") %>%
group_by(Cutoff) %>%
summarise(sample_mean = mean(Count),
sample_sd = sd(Count))
# summarise total
sumall <- dat %>%
filter(Abundance > 0) %>%
group_by(OTU) %>%
summarise(Abundance = mean(Abundance)) %>%
summarise(pct_0 = n(),
pct_0.1 = sum(Abundance < 0.1),
pct_0_1 = sum(Abundance >= 0.1 & Abundance < 1),
pct_1_10 = sum(Abundance >= 1 & Abundance < 10),
pct_10 = sum(Abundance > 10)) %>%
pivot_longer(cols = everything(),
names_to = c("Cutoff"),
values_to = "Count")
# Combine
output <- full_join(sumall, sumsample)
output$Cutoff <- c("All", "n < 0.1%", "0.1% < n < 1.0%", "1.0% < n < 10%", "10%  < n")
# Create output table
kable(output, row.names = F,digits = 2, caption = 'Count of phyla in general and per sample',align = "r") %>%
kable_classic(full_width = F, position = "left")
# Filter by abundance, then rank
phy.top <- filter_abundance(phy.rel) %>% filter_rank(min.rank = 19)
#Melt data
dat <- suppressWarnings(psmelt(phy.top))
colnames(dat)[c(1,4)] <- c("Taxa","SampleID")
# Sort taxa
dat.sort <- sort_taxa(dat)
# load data
load("R_objects/Agglomerated.RData")
params <- readRDS("R_objects/params_description.RDS")
# Transform data
phy.rel <- transform_sample_counts(phy.cl, fun = function(x) x/sum(x)*100)
dat <- psmelt(phy.rel)
# summarise per sample
sumsample <- dat %>%
filter(Abundance > 0) %>%
group_by(Sample) %>%
summarise(pct_0 = n(),
pct_0.1 = sum(Abundance < 0.1),
pct_0_1 = sum(Abundance >= 0.1 & Abundance < 1),
pct_1_10 = sum(Abundance >= 1 & Abundance < 10),
pct_10 = sum(Abundance > 10)) %>%
pivot_longer(-Sample,
names_to = c("Cutoff"),
values_to = "Count") %>%
group_by(Cutoff) %>%
summarise(sample_mean = mean(Count),
sample_sd = sd(Count))
# summarise total
sumall <- dat %>%
filter(Abundance > 0) %>%
group_by(OTU) %>%
summarise(Abundance = mean(Abundance)) %>%
summarise(pct_0 = n(),
pct_0.1 = sum(Abundance < 0.1),
pct_0_1 = sum(Abundance >= 0.1 & Abundance < 1),
pct_1_10 = sum(Abundance >= 1 & Abundance < 10),
pct_10 = sum(Abundance > 10)) %>%
pivot_longer(cols = everything(),
names_to = c("Cutoff"),
values_to = "Count")
# Combine
output <- full_join(sumall, sumsample)
output$Cutoff <- c("All", "n < 0.1%", "0.1% < n < 1.0%", "1.0% < n < 10%", "10%  < n")
# Create output table
kable(output, row.names = F,digits = 2, caption = 'Count of classes in general and per sample') %>%
kable_classic(full_width = F, position = "left")
# Filter by abundance, then rank
phy.top <- filter_abundance(phy.rel) %>% filter_rank(min.rank = 19)
#Melt data
dat <- suppressWarnings(psmelt(phy.top))
colnames(dat)[c(1,4)] <- c("Taxa","SampleID")
# Sort taxa
dat.sort <- sort_taxa(dat)
knitr::opts_chunk$set(echo = TRUE)
library(GMHmicrobiome)
library(ggpubr)
library(kableExtra)
library(phyloseq)
library(rstatix)
library(vegan)
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
##### FIRST PART
# Load phyloseq metadata
load("R_objects/Phyloseq_harsh.Rdata")
# Extract sample data from phyloseq object
dat <- as_tibble(sample_data(phy))
# Take a glimpse
glimpse(dat)
# Make a explorative summary
skimr::skim(dat)
if (!requireNamespace("remotes")) install.packages("remotes")
remotes::install_github("MSMortensen/GMHmicrobiome")
if (!requireNamespace("remotes")) install.packages("remotes")
remotes::install_github("MSMortensen/GMHmicrobiome")
detach("package:GMHmicrobiome", unload = TRUE)
if (!requireNamespace("remotes")) install.packages("remotes")
remotes::install_github("MSMortensen/GMHmicrobiome")
if (!requireNamespace("remotes")) install.packages("remotes")
remotes::install_github("MSMortensen/GMHmicrobiome")
usethis::create_github_token(scopes = c("MSMortensen/GMHmicrobiome","caly"), description = "Used for microbiome data processing in GMH group", host = NULL)
usethis::edit_r_environ()
if (!requireNamespace("remotes")) install.packages("remotes")
remotes::install_github("MSMortensen/GMHmicrobiome")
library(GMHmicrobiome)
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
library(kableExtra)
# Save params
saveRDS(params, file = "R_objects/import_params.RDS")
params <- readRDS(file = "R_objects/import_params.RDS")
load("scripts/adiv.Rdata")
# Set indeces
INDECES <- as.vector(str_split(params$indeces,pattern = "\\|",simplify = TRUE))
## First phyloseq object
# load data
load("R_objects/Phyloseq.Rdata")
# Calculate data
adat <- calculate_alpha_diversity(phy, INDECES = INDECES)
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(GMHmicrobiome)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
library(kableExtra)
# Save params
saveRDS(params, file = "R_objects/import_params.RDS")
params <- readRDS(file = "R_objects/import_params.RDS")
load("scripts/adiv.Rdata")
# Set indeces
INDECES <- as.vector(str_split(params$indeces,pattern = "\\|",simplify = TRUE))
## First phyloseq object
# load data
load("R_objects/Phyloseq.Rdata")
# Calculate data
adat <- calculate_alpha_diversity(phy, INDECES = INDECES)
# Add data to phyloseq object
sample_data(phy) <- adat
# Save the phyloseq object
save(phy, INDECES, file="R_objects/Phyloseq.Rdata")
## Harsh phyloseq object
# load data
load("R_objects/Phyloseq_harsh.Rdata")
# Calculate data
adat <- Calculate_alpha_div(phy, methods = INDECES)
# Add data to phyloseq object
sample_data(phy) <- adat
# Save the phyloseq object
save(phy, INDECES, file="R_objects/Phyloseq_harsh.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
