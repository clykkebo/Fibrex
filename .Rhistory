load("R_objects/Decontam_tables.RData")
# table with number of ASVs classified as contaminants
with(contam.long, table(Method,Contaminant))
# Evaluate what you can agree to loose and then use that column. I will use the minimum.minimum
phy <- prune_taxa(contam.df$ASV[contam.df$Freq.none == FALSE], phy)
params <- readRDS("R_objects/import_params.RDS")
# load data
load("R_objects/cleaned.Rdata")
# Compare sequencing depth to sample type
df <- data.frame(sample_data(phy))
df <- df[order(df$reads),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=reads, color=type)) + geom_point()
suppressMessages(ggsave("plots/sequencing_depth.pdf"))
# Prep table for output
contam.df <- data.frame(row.names = taxa_names(phy))
# Set any sample with DNA below detection limit (or neg PCR controls) to half the lowest measured value
sample_data(phy)$quant_reading <- ifelse(sample_data(phy)$dna_conc == 0, min(sample_data(phy)$dna_conc[sample_data(phy)$dna_conc != 0])/2, sample_data(phy)$dna_conc)
# Both methods, no batches
contam.df$Prev.none <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE)
contam.df$Freq.none <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE)
contam.df$combined.none <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE)
contam.df$minimum.none <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE)
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "minimum")
contam.df$Freq.minimum <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "minimum")
contam.df$combined.minimum <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "minimum")
contam.df$minimum.minimum <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "minimum")
# Both methods, Batch product
contam.df$Prev.product <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "product")
contam.df$Freq.product <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "product")
contam.df$combined.product <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "product")
contam.df$minimum.product <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "product")
# Both methods, Batch minimum
contam.df$Prev.fisher <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "fisher")
contam.df$Freq.fisher <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "fisher")
contam.df$combined.fisher <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "fisher")
contam.df$minimum.fisher <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "fisher")
# decontam summary
contam.df$ASV <- row.names(contam.df)
contam.long <- pivot_longer(contam.df, !ASV, names_to = "Method", values_to = "Contaminant")
# Merge with sample data
ps.prc <- transform_sample_counts(phy, function(x) 100*x/sum(x))
prc.melt <- suppressWarnings(psmelt(ps.prc))
prc.m <- full_join(prc.melt, contam.long, by = c("OTU" = "ASV"))
# Aggregate and plot
prc.agg <- prc.m %>% group_by(Sample, type, Method, Contaminant) %>% summarise(Abundance = sum(Abundance))
decontam.plot <- ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  + ggsci::scale_color_d3(palette = "category20")
suppressMessages(ggsave(decontam.plot,file = "plots/contaminant_fraction_multiple.png",device = "png"))
# save data to avoid rerunning for each knitting
save(contam.df, contam.long, file = "R_objects/Decontam_tables.RData")
load("R_objects/Decontam_tables.RData")
# table with number of ASVs classified as contaminants
with(contam.long, table(Method,Contaminant))
# Evaluate what you can agree to loose and then use that column. I will use the minimum.minimum
phy <- prune_taxa(contam.df$ASV[contam.df$Freq.none == FALSE], phy)
phy.harsh <- prune_taxa(contam.df$ASV[contam.df$Freq.product == FALSE], phy)
# Filter ASVs with less than 5 reads
phy <- prune_taxa(taxa_sums(phy) >= 5,phy)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
# Plot depth v type again
df <- data.frame(sample_data(phy))
df$depth <- sample_sums(phy)
df <- df[order(df$depth),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap(params$batch, nrow = 1) + ggtitle("Sequencing depth after Decontam")
# Plot depth v type again
df <- data.frame(sample_data(phy.harsh))
df$depth <- sample_sums(phy.harsh)
df <- df[order(df$depth),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap(params$batch, nrow = 1) + ggtitle("Sequencing depth after harsh Decontam")
# Remove samples with few reads and filter taxa again
phy <- prune_samples(sample_sums(phy) > 1000, phy)
phy.harsh <- prune_samples(sample_sums(phy.harsh) > 1000, phy.harsh)
# save the cleaned phyloseq object (extra objects, like harsh can be included as needed)
save(phy, phy.harsh, file="R_objects/Decontam.Rdata")
# Create csv with ASV abundance, taxonomy, and contaminant classification
tmp.phy <- suppressWarnings(merge_samples(ps.prc, "type"))
tmp.phy <- transform_sample_counts(tmp.phy, function(x) x/sum(x)*100)
tmp.samples <- data.frame(cbind(tax_table(tmp.phy), t(otu_table(tmp.phy))))
tmp.samples$ASV <- row.names(tmp.samples)
tmp.contam <- data.frame(ASV = contam.df$ASV, contam_phy = contam.df$minimum.minimum, contam_harsh = contam.df$Freq.product)
tmp.out <- full_join(tmp.samples, tmp.contam, by = "ASV")
write_csv(tmp.out,file = "output/Decontam_Overview.csv")
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
params <- readRDS("R_objects/import_params.RDS")
# load data
load("R_objects/Decontam.Rdata")
# Subset mocks
mocks <- subset_samples(phy, type == "Mock")
mocks <- prune_taxa(taxa_sums(mocks) >= 5, mocks)
# Control for depth of mocks
table(sample_sums(mocks))
# All fine, so transform to percentages
mocks.prc <- transform_sample_counts(mocks,fun = function(x) x*100/sum(x))
# Import original mock community data
mock.org <- readRDS("ZymoMock.RDS")
data("ZymoMock")
mock.org.clean <- aggregate(Abundance ~ Sample + Family, data = mock.org, FUN = sum)
# melt mocks
mock <- suppressWarnings(psmelt(mocks.prc))
mock <- mock[mock$Abundance > 0,]
mock.clean <- mock[,c("Sample","Abundance","Family")]
# Remove families not in mock
mock.clean$Family <- ifelse(mock.clean$Family %in% mock.org.clean$Family, mock.clean$Family, NA)
# Bind the data
mock.clean <- rbind(mock.clean,mock.org.clean)
mock.ag <- mock.clean %>% group_by(Sample, Family) %>% summarise(Abundance = sum(Abundance))
# Create plots
mock.plot <- ggbarplot(mock.ag, x = "Sample", y = "Abundance", fill = "Family", palette = "npg",rotate=TRUE, ylab = FALSE)
suppressMessages(ggsave("plots/test_mock_comparison.png",mock.plot,device = "png"))
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
params <- readRDS("R_objects/import_params.RDS")
# load data
load("R_objects/cleaned.Rdata")
params <- readRDS("R_objects/import_params.RDS")
# load data
load("R_objects/cleaned.Rdata")
# Compare sequencing depth to sample type
df <- data.frame(sample_data(phy))
df <- df[order(df$reads),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=reads, color=type)) + geom_point()
suppressMessages(ggsave("plots/sequencing_depth.pdf"))
# Prep table for output
contam.df <- data.frame(row.names = taxa_names(phy))
# Set any sample with DNA below detection limit (or neg PCR controls) to half the lowest measured value
sample_data(phy)$quant_reading <- ifelse(sample_data(phy)$dna_conc == 0, min(sample_data(phy)$dna_conc[sample_data(phy)$dna_conc != 0])/2, sample_data(phy)$dna_conc)
# Both methods, no batches
contam.df$Prev.none <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE)
contam.df$Freq.none <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE)
contam.df$combined.none <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE)
contam.df$minimum.none <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE)
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "minimum")
contam.df$Freq.minimum <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "minimum")
contam.df$combined.minimum <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "minimum")
contam.df$minimum.minimum <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "minimum")
# Both methods, Batch product
contam.df$Prev.product <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "product")
contam.df$Freq.product <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "product")
contam.df$combined.product <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "product")
contam.df$minimum.product <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "product")
# Both methods, Batch minimum
contam.df$Prev.fisher <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "fisher")
contam.df$Freq.fisher <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "fisher")
contam.df$combined.fisher <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "fisher")
contam.df$minimum.fisher <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "Run", batch.combine = "fisher")
# decontam summary
contam.df$ASV <- row.names(contam.df)
contam.long <- pivot_longer(contam.df, !ASV, names_to = "Method", values_to = "Contaminant")
# Merge with sample data
ps.prc <- transform_sample_counts(phy, function(x) 100*x/sum(x))
prc.melt <- suppressWarnings(psmelt(ps.prc))
prc.m <- full_join(prc.melt, contam.long, by = c("OTU" = "ASV"))
# Aggregate and plot
prc.agg <- prc.m %>% group_by(Sample, type, Method, Contaminant) %>% summarise(Abundance = sum(Abundance))
decontam.plot <- ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  + ggsci::scale_color_d3(palette = "category20")
suppressMessages(ggsave(decontam.plot,file = "plots/contaminant_fraction_multiple.png",device = "png"))
# save data to avoid rerunning for each knitting
save(contam.df, contam.long, file = "R_objects/Decontam_tables.RData")
load("R_objects/Decontam_tables.RData")
# table with number of ASVs classified as contaminants
with(contam.long, table(Method,Contaminant))
# Evaluate what you can agree to loose and then use that column. I will use the minimum.minimum
phy <- prune_taxa(contam.df$ASV[contam.df$Freq.minimum == FALSE], phy)
phy.harsh <- prune_taxa(contam.df$ASV[contam.df$Freq.product == FALSE], phy)
# Filter ASVs with less than 5 reads
phy <- prune_taxa(taxa_sums(phy) >= 5,phy)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
# Plot depth v type again
df <- data.frame(sample_data(phy))
df$depth <- sample_sums(phy)
df <- df[order(df$depth),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap(params$batch, nrow = 1) + ggtitle("Sequencing depth after Decontam")
# Plot depth v type again
df <- data.frame(sample_data(phy.harsh))
df$depth <- sample_sums(phy.harsh)
df <- df[order(df$depth),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap(params$batch, nrow = 1) + ggtitle("Sequencing depth after harsh Decontam")
# Remove samples with few reads and filter taxa again
phy <- prune_samples(sample_sums(phy) > 1000, phy)
phy.harsh <- prune_samples(sample_sums(phy.harsh) > 1000, phy.harsh)
# save the cleaned phyloseq object (extra objects, like harsh can be included as needed)
save(phy, phy.harsh, file="R_objects/Decontam.Rdata")
# Create csv with ASV abundance, taxonomy, and contaminant classification
tmp.phy <- suppressWarnings(merge_samples(ps.prc, "type"))
tmp.phy <- transform_sample_counts(tmp.phy, function(x) x/sum(x)*100)
tmp.samples <- data.frame(cbind(tax_table(tmp.phy), t(otu_table(tmp.phy))))
tmp.samples$ASV <- row.names(tmp.samples)
tmp.contam <- data.frame(ASV = contam.df$ASV, contam_phy = contam.df$minimum.minimum, contam_harsh = contam.df$Freq.product)
tmp.out <- full_join(tmp.samples, tmp.contam, by = "ASV")
write_csv(tmp.out,file = "output/Decontam_Overview.csv")
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
params <- readRDS("R_objects/import_params.RDS")
# load data
load("R_objects/Decontam.Rdata")
# Subset mocks
mocks <- subset_samples(phy, type == "Mock")
mocks <- prune_taxa(taxa_sums(mocks) >= 5, mocks)
# Control for depth of mocks
table(sample_sums(mocks))
# All fine, so transform to percentages
mocks.prc <- transform_sample_counts(mocks,fun = function(x) x*100/sum(x))
# Import original mock community data
mock.org <- readRDS("ZymoMock.RDS")
data("ZymoMock")
mock.org.clean <- aggregate(Abundance ~ Sample + Family, data = mock.org, FUN = sum)
# melt mocks
mock <- suppressWarnings(psmelt(mocks.prc))
mock <- mock[mock$Abundance > 0,]
mock.clean <- mock[,c("Sample","Abundance","Family")]
# Remove families not in mock
mock.clean$Family <- ifelse(mock.clean$Family %in% mock.org.clean$Family, mock.clean$Family, NA)
# Bind the data
mock.clean <- rbind(mock.clean,mock.org.clean)
mock.ag <- mock.clean %>% group_by(Sample, Family) %>% summarise(Abundance = sum(Abundance))
# Create plots
mock.plot <- ggbarplot(mock.ag, x = "Sample", y = "Abundance", fill = "Family", palette = "npg",rotate=TRUE, ylab = FALSE)
suppressMessages(ggsave("plots/test_mock_comparison.png",mock.plot,device = "png"))
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
# load
load("R_objects/Decontam.Rdata")
# Set alpha diversity indexes to use
R.methods <- c("Observed", "Shannon")
# calculate rarefaction data
Rdat <- Rcurve_data(phy, methods = R.methods)
# calculate rarefaction data
Rdat <- Rcurve_data(phy, methods = R.methods)
# calculate rarefaction data
Rdat <- Rcurve_data(phy, methods = R.methods)
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
library(kableExtra)
# Save params
saveRDS(params, file = "R_objects/import_params.RDS")
# load
load("R_objects/Decontam.Rdata")
# Set alpha diversity indexes to use
R.methods <- c("Observed", "Shannon")
# calculate rarefaction data
Rdat <- Rcurve_data(phy, methods = R.methods)
################################################################################
# load data
load("R_objects/input.Rdata")
# Clean phyloseq object
phy <- clean_taxa(phy, tax_remove = "Phylum", verbose = TRUE)
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
library(kableExtra)
# Save params
saveRDS(params, file = "R_objects/import_params.RDS")
knitr::opts_chunk$set(echo = TRUE ,warning = FALSE, message = FALSE)
# Load libraries
library(tidyverse)
library(phyloseq)
library(decontam)
library(pals)
library(ggpubr)
library(vegan)
library(phangorn)
library(kableExtra)
# Create used folders if missing
if (!file.exists("R_objects")) dir.create(file.path(getwd(), "R_objects"))
if (!file.exists("plots")) dir.create(file.path(getwd(), "plots"))
if (!file.exists("tables")) dir.create(file.path(getwd(), "tables"))
if (!file.exists("scripts")) dir.create(file.path(getwd(), "scripts"))
if (!file.exists("output")) dir.create(file.path(getwd(), "output"))
# Save params
saveRDS(params, file = "R_objects/import_params.RDS")
clean_taxa <- function(physeq, tax_remove = "Phylum", verbose = TRUE) {
tax <- data.frame(tax_table(physeq))
# list ASVs that should be removed
remove <- is.na(tax[,tax_remove])
# remove ASVs
phy.out <- prune_taxa(!remove, physeq)
# Calculate and print statistics
if (verbose) {
# Calculate sample sums of original and cleaned
output <- data.frame(row.names = sample_names(physeq),
org = sample_sums(physeq),
cleaned = sample_sums(phy.out))
output$removed <- output$org - output$cleaned
output$prc_removed <- output$removed*100/output$org
# Print output
cat("OVERVIEW OF ASVs REMOVED:\n",
"Removed ASVs (%):\t",
sum(remove),
" (",
round(sum(remove)*100/nrow(tax), digits = 3),
")\n",
"Removed reads (%):\t",
sum(output$removed),
" (",
round(sum(output$removed)*100/sum(output$org), digits = 3),
")\n",
"Mean abundance removed:\t",
round(mean(output$prc_removed), digits = 3),"\n",
"Max abundance removed:\t",
round(max(output$prc_removed), digits = 3),"\n", sep = "")
}
# Remove NA from tax table
tax <- data.frame(tax_table(phy.out))
for (i in seq(nrow(tax))) {
if (is.na(tax[i,1])) {tax[i,1:7] <- "Unknown"
} else if (is.na(tax[i,2])) {tax[i,2:7] <- paste(colnames(tax)[1],tax[i,1], sep = "_")
} else if (is.na(tax[i,3])) {tax[i,3:7] <- paste(colnames(tax)[2],tax[i,2], sep = "_")
} else if (is.na(tax[i,4])) {tax[i,4:7] <- paste(colnames(tax)[3],tax[i,3], sep = "_")
} else if (is.na(tax[i,5])) {tax[i,5:7] <- paste(colnames(tax)[4],tax[i,4], sep = "_")
} else if (is.na(tax[i,6])) {tax[i,6:7] <- paste(colnames(tax)[5],tax[i,5], sep = "_")
} else if (is.na(tax[i,7])) {tax[i,7] <- paste(colnames(tax)[6],tax[i,6], sep = "_")
}
}
# Insert modified tax_table in phyloseq object
tax_table(phy.out) <- as.matrix(tax)
# return the clean phyloseq object
return(phy.out)
}
# Save function
save(clean_taxa, file = "scripts/clean_tax.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
# Rarefaction curves
Rcurve_data <- function(physeq, ntables=10, step=250,maxdepth = max(sample_sums(physeq)), methods=c("Observed","Chao1","ACE","Shannon"), seedstart=500, verbose=FALSE) {
require("vegan")
# prep list of
step.seq <- seq(from = 1, to = maxdepth, by = step)
# Calculate alpha diversity
rare_tab <- lapply(step.seq,function(k) Calculate_alpha_div(physeq = physeq, ntables = ntables, depth = k, methods = methods, seedstart = seedstart, verbose = verbose))
# Format table
rare_tab <- do.call(rbind, rare_tab)
return(rare_tab)
}
# Calculate alpha diversity
Calculate_alpha_div <- function(physeq, ntables=100, depth = round(min(sample_sums(physeq))*0.9), methods=c("Observed","Chao1","ACE","Shannon"), seedstart=500, verbose=FALSE) {
require("vegan")
# remove samples below depth
phy.use <- prune_samples(sample_sums(physeq) >= depth, physeq )
# Orientate the OTU correctly
if (taxa_are_rows(phy.use)){otu.tab<-unclass(t(otu_table(phy.use)))} else otu.tab <- unclass(otu_table(phy.use))
# Rarefaction function
rarefy <- function(x, depth) {
y <- sample(rep(1:length(x), x), depth)
y.tab <- table(y)
j <- numeric(length(x))
j[as.numeric(names(y.tab))] <- y.tab
j
}
# Table to output alpha diversity table
Alpha_diversity = data.frame(row.names = row.names(otu.tab))
for (i in seq(length(methods))){
Alpha_diversity[,methods[i]] <- numeric(length = nrow(otu.tab))
Alpha_diversity[,paste0(methods[i],"_sd")] <- numeric(length = nrow(otu.tab))
}
# Run each sample separately
for (z in 1:nrow(otu.tab)) {
if (verbose==TRUE) {
print(paste("Rarefaction sample number", z, sep=" "))
}
numbers <- otu.tab[z,]
# Rarefy the sample ntables times
set.seed(seedstart + z)
rare_tab <- lapply(1:ntables,function(k) rarefy(numbers,depth))
# Format table
rare_tab <- do.call(rbind, rare_tab)
# Calculate Observed richness, Chao1, and ACE.
adiv <- data.frame(t(estimateR(rare_tab)))
if ("Observed" %in% methods){
# Save mean and sd of observed richness
Alpha_diversity$Observed[z] <- mean(adiv$S.obs)
Alpha_diversity$Observed_sd[z] <- sd(adiv$S.obs)
}
if ("Chao1" %in% methods){
# Save mean and sd of observed richness
Alpha_diversity$Chao1[z] <- mean(adiv$S.chao1)
Alpha_diversity$Chao1_sd[z] <- sd(adiv$S.chao1)
}
if ("ACE" %in% methods){
# Save mean and sd of observed richness
Alpha_diversity$ACE[z] <- mean(adiv$se.ACE)
Alpha_diversity$ACE_sd[z] <- sd(adiv$se.ACE)
}
if ("Shannon" %in% methods){
# Calculate observed richness for each rep of sample z
adiv <- vegan::diversity(rare_tab, index = "shannon")
# Save mean and sd of observed richness
Alpha_diversity$Shannon[z] <- mean(adiv)
Alpha_diversity$Shannon_sd[z] <- sd(adiv)
}
if ("Simpson" %in% methods){
# Calculate observed richness for each rep of sample z
adiv <- diversity(rare_tab, index = "simpson")
# Save mean and sd of observed richness
Alpha_diversity$Simpson[z] <- mean(adiv)
Alpha_diversity$Simpson_sd[z] <- sd(adiv)
}
if ("Evenness" %in% methods){
# Calculate observed richness for each rep of sample z
sha <- diversity(rare_tab, index = "shannon")
obs <- rowSums(rare_tab != 0)
adiv <- sha/log(obs)
# Save mean and sd of observed richness
Alpha_diversity$Evenness[z] <- mean(adiv)
Alpha_diversity$Evenness_sd[z] <- sd(adiv)
}
}
# Add alpha diversity to sample data
output <- cbind(sample_data(phy.use),Alpha_diversity)
output$depth = depth
# Return physeq to the environment
return(output)
}
# save functions
save(Calculate_alpha_div, Rcurve_data, file = "scripts/adiv.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
params <- readRDS("R_objects/import_params.RDS")
# Load analysis data
load(params$input)
# Create sample ID variable and use it as sample_names
sample_data(phy)$SampleID <- with(sample_data(phy), paste(Seq_run,Sample, sep = "_"))
sample_names(phy) <- sample_data(phy)$SampleID
# Create variables identifying negative controls. If negative controls are named differently update this option, "|" can be used to list more options
sample_data(phy)$is.neg <- grepl(params$neg,sample_data(phy)$Sample,ignore.case = TRUE)
# Create variables identifying sample types.Remember to update if Mock samples samples are named differently
sample_data(phy)$type <- ifelse(sample_data(phy)$is.neg, "Control",
ifelse(grepl("Mock",sample_data(phy)$Sample,
ignore.case = TRUE), "Mock","Sample"))
# Create backup of the original dataset
phy.org <- phy
# export sample data
tmp <- data.frame(sample_data(phy))
# Load metadata - This part will be specific to the project
meta <- read_csv(params$meta)
# Create an identical ID variable to use for merging
meta$SampleID <- with(meta, paste(Run,sample_name, sep = "_"))
# Verify that all the IDs are identical between the datasets
if (nrow(anti_join(tmp, meta, by = "SampleID")) != 0) {
anti_join(tmp, meta, by = "SampleID")
} else message("All samples from sequencing data matched in metadata")
if (nrow(anti_join(meta, tmp, by = "SampleID")) != 0) {
anti_join(meta, tmp, by = "SampleID")
} else message("All samples from metadata matched in sequencing data")
# Check which, if any columns, are in both tables
shared_cols <- colnames(tmp)[colnames(tmp) %in% colnames(meta)] %>% .[. != "SampleID"]
# Print shared columns
if (length(shared_cols) != 0) message("The following columns are present in both sequencing and metadata:\n", knitr::combine_words(shared_cols))
# If any other columns than ID is in both, consider if you want it removed
meta <- meta %>% select(-one_of(shared_cols))
# When you are sure that all match, then merge and add to phyloseq
mtmp <- left_join(tmp,meta,by="SampleID")
row.names(mtmp) <- mtmp$SampleID
# Add the merged data to the phyloseq object
sample_data(phy) <- mtmp
# Save the phyloseq object
save(phy.org, phy, file="R_objects/input.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
################################################################################
# load data
load("R_objects/input.Rdata")
# Clean phyloseq object
phy <- clean_taxa(phy, tax_remove = "Phylum", verbose = TRUE)
library("phyloseq")
################################################################################
# load data
load("R_objects/input.Rdata")
# Clean phyloseq object
phy <- clean_taxa(phy, tax_remove = "Phylum", verbose = TRUE)
################################################################################
# load data
load("R_objects/input.Rdata")
# Clean phyloseq object
phy <- clean_taxa(phy, tax_remove = "Phylum", verbose = TRUE)
?clean_Taxa
?clean_axa
?clean_taxa
?clean_taxa()
