rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
# Rarefaction curves
Rcurve_data <- function(physeq, ntables=10, step=250,maxdepth = max(sample_sums(physeq)), methods=c("Observed","Chao1","ACE","Shannon"), seedstart=500, verbose=FALSE) {
require("vegan")
# prep list of
step.seq <- seq(from = 1, to = maxdepth, by = step)
# Calculate alpha diversity
rare_tab <- lapply(step.seq,function(k) Calculate_alpha_div(physeq = physeq, ntables = ntables, depth = k, methods = methods, seedstart = seedstart, verbose = verbose))
# Format table
rare_tab <- do.call(rbind, rare_tab)
return(rare_tab)
}
# Calculate alpha diversity
Calculate_alpha_div <- function(physeq, ntables=100, depth = round(min(sample_sums(physeq))*0.9), methods=c("Observed","Chao1","ACE","Shannon"), seedstart=500, verbose=FALSE) {
require("vegan")
# remove samples below depth
phy.use <- prune_samples(sample_sums(physeq) >= depth, physeq )
# Orientate the OTU correctly
if (taxa_are_rows(phy.use)){otu.tab<-unclass(t(otu_table(phy.use)))} else otu.tab <- unclass(otu_table(phy.use))
# Rarefaction function
rarefy <- function(x, depth) {
y <- sample(rep(1:length(x), x), depth)
y.tab <- table(y)
j <- numeric(length(x))
j[as.numeric(names(y.tab))] <- y.tab
j
}
# Table to output alpha diversity table
Alpha_diversity = data.frame(row.names = row.names(otu.tab))
for (i in seq(length(methods))){
Alpha_diversity[,methods[i]] <- numeric(length = nrow(otu.tab))
Alpha_diversity[,paste0(methods[i],"_sd")] <- numeric(length = nrow(otu.tab))
}
# Run each sample separately
for (z in 1:nrow(otu.tab)) {
if (verbose==TRUE) {
print(paste("Rarefaction sample number", z, sep=" "))
}
numbers <- otu.tab[z,]
# Rarefy the sample ntables times
set.seed(seedstart + z)
rare_tab <- lapply(1:ntables,function(k) rarefy(numbers,depth))
# Format table
rare_tab <- do.call(rbind, rare_tab)
# Calculate Observed richness, Chao1, and ACE.
adiv <- data.frame(t(estimateR(rare_tab)))
if ("Observed" %in% methods){
# Save mean and sd of observed richness
Alpha_diversity$Observed[z] <- mean(adiv$S.obs)
Alpha_diversity$Observed_sd[z] <- sd(adiv$S.obs)
}
if ("Chao1" %in% methods){
# Save mean and sd of observed richness
Alpha_diversity$Chao1[z] <- mean(adiv$S.chao1)
Alpha_diversity$Chao1_sd[z] <- sd(adiv$S.chao1)
}
if ("ACE" %in% methods){
# Save mean and sd of observed richness
Alpha_diversity$ACE[z] <- mean(adiv$se.ACE)
Alpha_diversity$ACE_sd[z] <- sd(adiv$se.ACE)
}
if ("Shannon" %in% methods){
# Calculate observed richness for each rep of sample z
adiv <- diversity(rare_tab, index = "shannon")
# Save mean and sd of observed richness
Alpha_diversity$Shannon[z] <- mean(adiv)
Alpha_diversity$Shannon_sd[z] <- sd(adiv)
}
if ("Simpson" %in% methods){
# Calculate observed richness for each rep of sample z
adiv <- diversity(rare_tab, index = "simpson")
# Save mean and sd of observed richness
Alpha_diversity$Simpson[z] <- mean(adiv)
Alpha_diversity$Simpson_sd[z] <- sd(adiv)
}
if ("Evenness" %in% methods){
# Calculate observed richness for each rep of sample z
sha <- diversity(rare_tab, index = "shannon")
obs <- rowSums(rare_tab != 0)
adiv <- sha/log(obs)
# Save mean and sd of observed richness
Alpha_diversity$Evenness[z] <- mean(adiv)
Alpha_diversity$Evenness_sd[z] <- sd(adiv)
}
}
# Add alpha diversity to sample data
output <- cbind(sample_data(phy.use),Alpha_diversity)
output$depth = depth
# Return physeq to the environment
return(output)
}
# save functions
save(Calculate_alpha_div, Rcurve_data, file = "scripts/adiv.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
# Load analysis data
load("output/fibrex.merged.phyloseq_object.RData")
# Create sample ID variable and use it as sample_names
sample_data(phy)$ID <- sample_names(phy)
# Create variables identifying negative controls. If negative controls are named differently update this option, "|" can be used to list more options
sample_data(phy)$is.neg <- grepl("WTR",sample_data(phy)$ID,ignore.case = TRUE)
# Create variables identifying sample types.Remember to update if Mock samples samples are named differently
sample_data(phy)$type <- ifelse(sample_data(phy)$is.neg, "Control",
ifelse(grepl("Mock",sample_data(phy)$ID,
ignore.case = TRUE), "Mock","Sample"))
# Create backup of the original dataset
phy.org <- phy
# export sample data
tmp <- data.frame(sample_data(phy))
# Load metadata - This part will be specific to the project
meta <- read.table("metadata.csv", header = T, sep = ";")
meta$sampleID[grepl("MOCK",meta$sampleID)] <- str_replace(meta$sampleID[grepl("MOCK",meta$sampleID)], "MOCK","Mock")
# Verify that all the IDs are identical between the datasets
nrow(tmp[!tmp$ID %in% meta$sampleID,])
nrow(meta[!meta$sampleID %in% tmp$ID,])
# Check which, if any columns, are in both tables
colnames(tmp)[colnames(tmp) %in% colnames(meta)]
# When you are sure that all match, then merge and add to phyloseq
mtmp <- merge(tmp,meta,by.x="ID",by.y = "sampleID", all.x = TRUE, all.y = FALSE)
row.names(mtmp) <- mtmp$ID
# Add the merged data to the phyloseq object
sample_data(phy) <- mtmp
head(sample_data(phy))
head(tmp)
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
# Load analysis data
load("output/fibrex.merged.phyloseq_object.RData")
# Create sample ID variable and use it as sample_names
sample_data(phy)$ID <- sample_names(phy)
# Create variables identifying negative controls. If negative controls are named differently update this option, "|" can be used to list more options
sample_data(phy)$is.neg <- grepl("WTR",sample_data(phy)$ID,ignore.case = TRUE)
# Create variables identifying sample types.Remember to update if Mock samples samples are named differently
sample_data(phy)$type <- ifelse(sample_data(phy)$is.neg, "Control",
ifelse(grepl("Mock",sample_data(phy)$ID,
ignore.case = TRUE), "Mock","Sample"))
# Create backup of the original dataset
phy.org <- phy
# export sample data
tmp <- data.frame(sample_data(phy))
head(tmp)
# Load metadata - This part will be specific to the project
meta <- read.table("metadata.csv", header = T, sep = ";")
head(meta)
# Verify that all the IDs are identical between the datasets
nrow(tmp[!tmp$ID %in% meta$sampleID,])
nrow(meta[!meta$sampleID %in% tmp$ID,])
# Verify that all the IDs are identical between the datasets
nrow(tmp[!tmp$Sample %in% meta$sampleID,])
nrow(meta[!meta$sampleID %in% tmp$Sample,])
meta[!meta$sampleID %in% tmp$Sample,]
meta$sampleID[grepl("MOCK",meta$sampleID)] <- str_replace(meta$sampleID[grepl("MOCK",meta$sampleID)], "MOCK","Mock")
# Verify that all the IDs are identical between the datasets
nrow(tmp[!tmp$Sample %in% meta$sampleID,])
nrow(meta[!meta$sampleID %in% tmp$Sample,])
# Check which, if any columns, are in both tables
colnames(tmp)[colnames(tmp) %in% colnames(meta)]
# When you are sure that all match, then merge and add to phyloseq
mtmp <- merge(tmp,meta,by.x="Sample",by.y = "sampleID", all.x = TRUE, all.y = FALSE)
row.names(mtmp) <- mtmp$ID
head(mtmp)
# When you are sure that all match, then merge and add to phyloseq
mtmp <- merge(tmp,meta,by.x="Sample",by.y = "sampleID", all.x = TRUE, all.y = FALSE)
row.names(mtmp) <- mtmp$ID
# Add the merged data to the phyloseq object
sample_data(phy) <- mtmp
# Save the phyloseq object
save(phy.org, phy, file="R_objects/input.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
################################################################################
# load data
load("R_objects/input.Rdata")
# Load function
load("scripts/clean_tax.Rdata")
# Clean phyloseq object
phy <- clean_taxa(phy, tax_remove = "Phylum", verbose = TRUE)
# Save cleaned phyloseq object
save(phy.org, phy, file="R_objects/cleaned.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
################################################################################
# load data
load("R_objects/cleaned.Rdata")
### If using prevalence based method
# Compare sequencing depth to sample type
df <- data.frame(sample_data(phy))
df <- df[order(df$reads),]
################################################################################
# load data
load("R_objects/input.Rdata")
# Load function
load("scripts/clean_tax.Rdata")
# Clean phyloseq object
phy <- clean_taxa(phy, tax_remove = "Phylum", verbose = TRUE)
# Save cleaned phyloseq object
save(phy.org, phy, file="R_objects/cleaned.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
invisible(gc()) #free up memory and report the memory usage.
# load data
load("R_objects/cleaned.Rdata")
# Compare sequencing depth to sample type
df <- data.frame(sample_data(phy))
df <- df[order(df$reads),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=reads, color=type)) + geom_point()
suppressMessages(ggsave("plots/sequencing_depth.pdf"))
ggplot(data=df, aes(x=Index, y=reads, color=type)) + geom_point()
# Prep table for output
contam.df <- data.frame(row.names = taxa_names(phy))
# Set any sample with DNA below detection limit (or neg PCR controls) to half the lowest measured value
sample_data(phy)$quant_reading <- ifelse(sample_data(phy)$dna_conc == 0, min(sample_data(phy)$dna_conc[sample_data(phy)$dna_conc != 0])/2, sample_data(phy)$dna_conc)
# Both methods, no batches
contam.df$Prev.none <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE)
# Both methods, no batches
contam.df$Prev.none <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE)
contam.df$Freq.none <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE)
contam.df$combined.none <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE)
contam.df$minimum.none <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE)
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "Run", batch.combine = "minimum")
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "minimum")
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "minimum")
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$Freq.minimum <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$Freq.minimum <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$combined.minimum <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$minimum.minimum <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
# Both methods, Batch product
contam.df$Prev.product <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "product")
# Both methods, Batch product
contam.df$Prev.product <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "product")
contam.df$Freq.product <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "product")
contam.df$combined.product <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "product")
contam.df$minimum.product <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "product")
# Both methods, Batch minimum
contam.df$Prev.fisher <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "fisher")
contam.df$Freq.fisher <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "fisher")
contam.df$combined.fisher <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "fisher")
contam.df$minimum.fisher <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "fisher")
# decontam summary
contam.df$ASV <- row.names(contam.df)
contam.long <- reshape2::melt(contam.df, id.vars = "ASV",variable.name = "Method",value.name = "Contaminant")
with(contam.long, table(Method,Contaminant))
# Merge with sample data
ps.prc <- transform_sample_counts(phy, function(x) 100*x/sum(x))
prc.melt <- psmelt(ps.prc)
prc.m <- merge(prc.melt, contam.long, by.y = "ASV", by.x = "OTU", all = TRUE)
# Aggregate and plot
prc.agg <- aggregate(Abundance ~ Sample+type+Method+Contaminant, data = prc.m, FUN = sum)
ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(prc.agg$Method)))))
ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(prc.agg$Method)))))
suppressMessages(ggsave("plots/contaminant_fraction_multiple.pdf"))
ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(prc.agg$Method)))))
aggregate(Abundance~Method+type, data = prc.agg[prc.agg$Contaminant,], FUN = mean)
# Evaluate what you can agree to loose and then use that column. I will use the minimum.minimum
phy.harsh <- prune_taxa(contam.df$ASV[contam.df$combined.product == FALSE], phy)
phy <- prune_taxa(contam.df$ASV[contam.df$minimum.minimum == FALSE], phy)
# Filter ASVs with less than 5 reads
phy <- prune_taxa(taxa_sums(phy) >= 5,phy)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
# Plot depth v type again
df <- data.frame(sample_data(phy))
df$depth <- sample_sums(phy)
df <- df[order(df$depth),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1)
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1)
# Remove samples with few reads and filter taxa again
phy <- prune_samples(sample_sums(phy) > 5000, phy)
phy.harsh <- prune_samples(sample_sums(phy.harsh) > 5000, phy.harsh)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
# save the cleaned phyloseq object (extra objects, like harsh can be included as needed)
save(phy, phy.harsh, file="R_objects/Decontam.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
# load data
load("R_objects/Decontam.Rdata")
# Subset mocks
mocks <- subset_samples(phy, type == "Mock")
mocks <- prune_taxa(taxa_sums(mocks) >= 5, mocks)
# Control for depth of mocks
table(sample_sums(mocks))
# All fine, so transform to percentages
mocks.prc <- transform_sample_counts(mocks,fun = function(x) x*100/sum(x))
# Define original mock
mock.org <- data.frame(Sample = "Original",Abundance = 5, Family_clean = c("Moraxellaceae", "Actinomycetaceae", "Bacillaceae_1", "Bacteroidaceae", "Clostridiaceae_1", "Deinococcaceae", "Enterococcaceae", "Enterobacteriaceae", "Helicobacteraceae", "Lactobacillaceae", "Listeriaceae", "Neisseriaceae", "Propionibacteriaceae", "Pseudomonadaceae", "Rhodobacteraceae", "Staphylococcaceae", "Staphylococcaceae", "Streptococcaceae", "Streptococcaceae", "Streptococcaceae"))
# Define anything not matching orginal mock families as NA
mock <- psmelt(mocks.prc)
mock <- mock[mock$Abundance > 0,]
mock$Family_clean <- ifelse(mock$Family %in% mock.org$Family_clean, mock$Family, NA)
# melt mocks
mock.clean <- mock[,c("Sample","Abundance","Family_clean")]
mock.clean <- rbind(mock.clean,mock.org)
# Create plots
ggplot(mock.clean, aes(Sample, Abundance, fill = Family_clean, color = Family_clean)) +
geom_col(position = "fill") + coord_flip() +
scale_fill_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean))))) +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean)))))
suppressMessages(ggsave("plots/mock_comparison.pdf"))
ggplot(mock.clean, aes(Sample, Abundance, fill = Family_clean, color = Family_clean)) +
geom_col(position = "fill") + coord_flip() +
scale_fill_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean))))) +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean)))))
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
```{r decontam_multiple, eval = FALSE}
# load data
load("R_objects/cleaned.Rdata")
# Compare sequencing depth to sample type
df <- data.frame(sample_data(phy))
df <- df[order(df$reads),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=reads, color=type)) + geom_point()
suppressMessages(ggsave("plots/sequencing_depth.pdf"))
# Prep table for output
contam.df <- data.frame(row.names = taxa_names(phy))
# Set any sample with DNA below detection limit (or neg PCR controls) to half the lowest measured value
sample_data(phy)$quant_reading <- ifelse(sample_data(phy)$dna_conc == 0, min(sample_data(phy)$dna_conc[sample_data(phy)$dna_conc != 0])/2, sample_data(phy)$dna_conc)
# Both methods, no batches
contam.df$Prev.none <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE)
# Both methods, no batches
contam.df$Prev.none <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE)
contam.df$Freq.none <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE)
contam.df$combined.none <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE)
contam.df$minimum.none <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE)
# Both methods, Batch minimum
contam.df$Prev.minimum <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$Freq.minimum <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$combined.minimum <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
contam.df$minimum.minimum <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "minimum")
# Both methods, Batch product
contam.df$Prev.product <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "product")
contam.df$Freq.product <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "product")
contam.df$combined.product <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "product")
contam.df$minimum.product <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "product")
# Both methods, Batch minimum
contam.df$Prev.fisher <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "fisher")
# Both methods, Batch minimum
contam.df$Prev.fisher <- isContaminant(phy, method="prevalence", neg="is.neg", detailed = FALSE, batch = "run", batch.combine = "fisher")
contam.df$Freq.fisher <- isContaminant(phy, method="frequency", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "fisher")
contam.df$combined.fisher <- isContaminant(phy, method="combined", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "fisher")
contam.df$minimum.fisher <- isContaminant(phy, method="minimum", neg="is.neg", conc="quant_reading", detailed = FALSE, batch = "run", batch.combine = "fisher")
# decontam summary
contam.df$ASV <- row.names(contam.df)
contam.long <- reshape2::melt(contam.df, id.vars = "ASV",variable.name = "Method",value.name = "Contaminant")
with(contam.long, table(Method,Contaminant))
# Merge with sample data
ps.prc <- transform_sample_counts(phy, function(x) 100*x/sum(x))
# Merge with sample data
ps.prc <- transform_sample_counts(phy, function(x) 100*x/sum(x))
prc.melt <- psmelt(ps.prc)
prc.m <- merge(prc.melt, contam.long, by.y = "ASV", by.x = "OTU", all = TRUE)
# Aggregate and plot
prc.agg <- aggregate(Abundance ~ Sample+type+Method+Contaminant, data = prc.m, FUN = sum)
ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(prc.agg$Method)))))
ggplot(prc.agg[prc.agg$Contaminant,], aes(x = type, y = Abundance,color = Method)) +
geom_boxplot()  +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(prc.agg$Method)))))
suppressMessages(ggsave("plots/contaminant_fraction_multiple.pdf"))
aggregate(Abundance~Method+type, data = prc.agg[prc.agg$Contaminant,], FUN = mean)
# Evaluate what you can agree to loose and then use that column. I will use the minimum.minimum
phy.harsh <- prune_taxa(contam.df$ASV[contam.df$combined.product == FALSE], phy)
phy <- prune_taxa(contam.df$ASV[contam.df$minimum.minimum == FALSE], phy)
# Evaluate what you can agree to loose and then use that column. I will use the minimum.minimum
phy.harsh <- prune_taxa(contam.df$ASV[contam.df$combined.product == FALSE], phy)
phy <- prune_taxa(contam.df$ASV[contam.df$minimum.minimum == FALSE], phy)
# Filter ASVs with less than 5 reads
phy <- prune_taxa(taxa_sums(phy) >= 5,phy)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
# Plot depth v type again
df <- data.frame(sample_data(phy))
df$depth <- sample_sums(phy)
df <- df[order(df$depth),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1)
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1)
ggplot(data=df, aes(x=Index, y=depth, color=type, )) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(depth, n = 10))
ggplot(data=df, aes(x=Index, y=depth, color=type, )) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(depth$y, n = 10))
ggplot(data=df, aes(x=Index, y=depth, color=type, )) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(y, n = 10))
ggplot(data=df, aes(x=Index, y=depth, color=type, )) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(df$depth, n = 10))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(df$depth, n = 12))
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(df$depth, n = 20))
tail(df$depth)
tail(df, sort(df$depth, x decreasing = TRUE))
tail(df, sort(df$depth, decreasing = TRUE))
tail(df, sort(df$depth, decreasing = FALSE))
tail(df$depth, sort(df$depth, decreasing = FALSE))
tail(df$Sample, sort(df$depth, decreasing = FALSE))
tail(df$Sample))
tail(df$Sample)
list(df$depth)
head(df)
head(df, n = 10)
head(df$Sample, n = 10)
head(df$Sample, n = 20)
head(df$depth, n = 20)
head(df$depth, n = 30)
head(df$depth$Sample, n = 30)
head(c(df$Sample,df$depth), n = 30)
head(c(df$Sample, df$depth), n = 30)
head(c(df$Sample, df$depth), n = 30)
head(select(df$Sample, df$depth), n = 30)
head(select(df$Sample, df$depth), n = 30)
head(select(df$Sample), n = 30)
head((df$Sample, df$depth), n = 30)
head(df$Sample, df$depth, n = 30)
head(df$Sample:df$depth, n = 30)
head(df$depth, n = 30)
View(df)
ggplot(data=df, aes(x=Index, y=depth, color=type)) + geom_point() +
facet_wrap("run", nrow = 1) +
scale_y_continuous(breaks = pretty(df$depth, n = 10))
# Remove samples with few reads and filter taxa again
phy <- prune_samples(sample_sums(phy) > 2800, phy)
phy.harsh <- prune_samples(sample_sums(phy.harsh) > 5000, phy.harsh)
phy.harsh <- prune_taxa(taxa_sums(phy.harsh) >= 5,phy.harsh)
# save the cleaned phyloseq object (extra objects, like harsh can be included as needed)
save(phy, phy.harsh, file="R_objects/Decontam.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
# load data
load("R_objects/Decontam.Rdata")
# Subset mocks
mocks <- subset_samples(phy, type == "Mock")
mocks <- prune_taxa(taxa_sums(mocks) >= 5, mocks)
# Control for depth of mocks
table(sample_sums(mocks))
# All fine, so transform to percentages
mocks.prc <- transform_sample_counts(mocks,fun = function(x) x*100/sum(x))
# Define original mock
mock.org <- data.frame(Sample = "Original",Abundance = 5, Family_clean = c("Moraxellaceae", "Actinomycetaceae", "Bacillaceae_1", "Bacteroidaceae", "Clostridiaceae_1", "Deinococcaceae", "Enterococcaceae", "Enterobacteriaceae", "Helicobacteraceae", "Lactobacillaceae", "Listeriaceae", "Neisseriaceae", "Propionibacteriaceae", "Pseudomonadaceae", "Rhodobacteraceae", "Staphylococcaceae", "Staphylococcaceae", "Streptococcaceae", "Streptococcaceae", "Streptococcaceae"))
# Define anything not matching orginal mock families as NA
mock <- psmelt(mocks.prc)
mock <- mock[mock$Abundance > 0,]
mock$Family_clean <- ifelse(mock$Family %in% mock.org$Family_clean, mock$Family, NA)
# melt mocks
mock.clean <- mock[,c("Sample","Abundance","Family_clean")]
mock.clean <- rbind(mock.clean,mock.org)
# Create plots
ggplot(mock.clean, aes(Sample, Abundance, fill = Family_clean, color = Family_clean)) +
geom_col(position = "fill") + coord_flip() +
scale_fill_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean))))) +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean)))))
suppressMessages(ggsave("plots/mock_comparison.pdf"))
ggplot(mock.clean, aes(Sample, Abundance, fill = Family_clean, color = Family_clean)) +
geom_col(position = "fill") + coord_flip() +
scale_fill_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean))))) +
scale_color_manual(values=unname(pals::polychrome(n=length(unique(mock.clean$Family_clean)))))
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
```{r clean_meta, eval=TRUE, echo=TRUE}
# load data
load("R_objects/Decontam.Rdata")
# Evaluate relevant variables
with(sample_data(phy), table(feed,day,treatment))
# Remove relevant samples and prune taxa
phy <- subset_samples(phy, type == "Sample")
phy <- prune_taxa(taxa_sums(phy) >=1,phy)
# save the cleaned phyloseq object
save(phy, file="R_objects/Phyloseq.Rdata")
# clear the environment and release memory
rm(list = ls(all.names = TRUE))
invisible(gc())
# load
load("R_objects/Phyloseq.Rdata")
load("scripts/adiv.Rdata")
# Set alpha diversity indexes to use
R.methods <- c("Observed", "Chao1", "Shannon", "ACE")
# Look at distribution of sequencing depths
quantile(sample_sums(phy),probs = seq(0,1,0.1))
# Set max depth to the 90th quantile
mdepth <- round(unname(quantile(sample_sums(phy),0.9)))
# calculate rarefaction data
Rdat <- Rcurve_data(phy, methods = R.methods, maxdepth = mdepth)
